# Ethik, Richtlinien und Regulierung von KI im Journalismus

> Recherche-Dokument, Stand: Februar 2026

---

## Inhaltsverzeichnis

1. [Richtlinien grosser Medienorganisationen](#1-richtlinien-grosser-medienorganisationen)
2. [EU AI Act und Journalismus](#2-eu-ai-act-und-journalismus)
3. [Transparenz- und Kennzeichnungspflichten](#3-transparenz--und-kennzeichnungspflichten)
4. [Urheberrechtsfragen bei KI-generierten Texten](#4-urheberrechtsfragen-bei-ki-generierten-texten)
5. [Datenschutz und Quellenschutz](#5-datenschutz-und-quellenschutz)
6. [Fallbeispiele: Wenn KI im Journalismus schiefgeht](#6-fallbeispiele-wenn-ki-im-journalismus-schiefgeht)
7. [Deutsche Regulierung und Richtlinien](#7-deutsche-regulierung-und-richtlinien)
8. [Quellen](#8-quellen)

---

## 1. Richtlinien grosser Medienorganisationen

### Associated Press (AP)

Die AP hat im August 2023 interne KI-Richtlinien veroeffentlicht. Kernpunkte:

- **Kein KI-generierter Content fuer den Nachrichtendienst**: KI darf nicht verwendet werden, um veroeffentlichbare Inhalte oder Bilder fuer den Nachrichtendienst zu erstellen.
- **Menschliche Verantwortung**: Journalisten bleiben fuer alle veroeffentlichten Inhalte verantwortlich.
- **Experimentierfreude bei interner Nutzung**: AP ermutigt Mitarbeitende, KI-Tools zu testen, aber nicht fuer die direkte Content-Produktion.

### Reuters

Reuters betrachtet KI als Innovation mit Potenzial, den Journalismus zu staerken:

- **Tradition technologischer Innovation**: Von Brieftauben ueber den Telegraphen bis zum Internet -- Reuters hat stets neue Technologien adaptiert.
- **Automatisierte Wirtschaftsberichterstattung**: Reuters nutzt bereits seit Jahren automatisierte Systeme fuer Wirtschaftsnachrichten.
- **Redaktionelle Standards gelten uneingeschraenkt**: "A Reuters story is a Reuters story" -- unabhaengig davon, wie der Inhalt erstellt wurde.
- **Menschliche Aufsicht**: Journalisten und Redakteure ueberwachen alle KI-erstellten Inhalte.

### BBC

Die BBC hat 2024 ihren ethischen Leitfaden fuer KI aktualisiert:

- **Editorial Guidelines gelten auch fuer KI**: Genauigkeit, Unparteilichkeit, Fairness und Privatsphaere bleiben die Leitwerte.
- **Begruendungspflicht**: Jeder KI-Einsatz muss durch die jeweilige Aufgabe gerechtfertigt sein.
- **Redaktionelle Verantwortung**: Es muss stets eine redaktionell verantwortliche Person die Entwicklung des Systems beaufsichtigen.
- **Transparenz gegenueber dem Publikum**: Das Publikum muss informiert werden, wenn KI im Spiel ist, inklusive Erklaerung von Grund und Art des KI-Einsatzes.

### New York Times (NYT)

Die NYT formuliert drei Grundprinzipien:

1. **KI kann journalistische Faehigkeiten verbessern** -- aber sie ersetzt keinen Journalismus.
2. **Menschliche Fuehrung und Aufsicht sind unabdingbar**.
3. **KI kann unterstuetzen, aber die Arbeit wird immer von Journalisten geleitet**, um Verantwortlichkeit und Genauigkeit sicherzustellen.

### Deutscher Presserat

Der Deutsche Presserat hat im September 2024 seine Position zur KI im Journalismus beschlossen (in Kraft seit 19. Maerz 2025):

- **Praeambel-Ergaenzung des Pressekodex**: Redaktionen tragen die presseethische Verantwortung fuer alle redaktionellen Beitraege -- unabhaengig von der Art der Erstellung, einschliesslich KI-generierter Inhalte.
- **Keine Kennzeichnungspflicht fuer KI-Texte**: Der Presserat haelt eine zusaetzliche Kennzeichnungspflicht fuer KI-generierte Texte derzeit nicht fuer erforderlich.
- **Kennzeichnungspflicht fuer KI-Bilder**: KI-generierte Bilder muessen als Symbolbilder gekennzeichnet werden, da nicht der Eindruck entstehen darf, sie bildeten die Realitaet ab.
- **Uneingeschraenkte redaktionelle Verantwortung**: Die presseethische Verantwortung liegt weiterhin vollstaendig bei den Redaktionen.

### Vergleich auf einen Blick

| Organisation | KI fuer Content erlaubt? | Kennzeichnungspflicht | Menschliche Aufsicht |
|---|---|---|---|
| AP | Nein (fuer Nachrichtendienst) | -- | Ja |
| Reuters | Ja, mit Aufsicht | Intern geregelt | Ja |
| BBC | Ja, mit Begruendung | Ja, gegenueber Publikum | Ja |
| NYT | Ja, als Unterstuetzung | Intern geregelt | Ja |
| Dt. Presserat | Kodex gilt auch fuer KI | Nur fuer Bilder | Ja |

---

## 2. EU AI Act und Journalismus

### Ueberblick

Die KI-Verordnung der EU (Regulation (EU) 2024/1689) trat am 1. August 2024 in Kraft. Sie ist das weltweit erste umfassende KI-Gesetz.

### Relevante Bestimmungen fuer den Journalismus

**Risikoklassifikation**: Medien sind derzeit **nicht** als Hochrisiko-Bereich eingestuft. Das bedeutet, dass die strengsten Regulierungen nicht direkt fuer Entwickler von Medien-KI-Systemen gelten. Die relevanteste Pflicht betrifft technische Dokumentation und Transparenz ueber die eingesetzten Modelle.

**Artikel 50 -- Kennzeichnung und Transparenz**:
- Anbieter von KI-Systemen muessen KI-generierte oder manipulierte Inhalte in maschinenlesbarem Format kennzeichnen.
- Nutzer, die generative KI fuer professionelle Zwecke einsetzen, muessen Deepfakes und KI-generierte Texte zu Themen von oeffentlichem Interesse klar kennzeichnen.

**Urheberrecht und Trainingsdaten**:
- Unternehmen muessen offenlegen, welche Inhalte fuer das Training von KI-Modellen verwendet wurden.
- Sie muessen europaeisches Urheberrecht einhalten.
- Ein Vorbehalt ("unless relevant copyright exceptions and limitations apply") koennte die Moeglichkeiten von Nachrichtenverlagen einschraenken, Autorisierung und Verguetung einzufordern.

**Zeitplan**:
- Die Transparenzpflichten fuer KI-generierte Inhalte werden am **2. August 2026** anwendbar.
- Der Code of Practice zur Umsetzung wird seit Ende 2025 mit knapp 1.000 Stakeholdern erarbeitet.

### Kritik aus der Medienbranche

- **Reporter ohne Grenzen (RSF)**: Warnt, dass das ohnehin fragile Geschaeftsmodell unabhaengiger Medien durch Urheberrechtsverletzungen und den Einsatz generativer KI weiter gefaehrdet wird.
- **European Federation of Journalists (EFJ)**: Kritisiert die ungleiche Beteiligung im Drafting-Prozess -- KI-Anbieter werden zu Workshops eingeladen, waehrend Akademiker und Zivilgesellschaft erst spaeter Feedback geben duerfen.

---

## 3. Transparenz- und Kennzeichnungspflichten

### EU-Ebene: Code of Practice

Am 17. Dezember 2025 wurde der erste Entwurf des **Code of Practice zur Transparenz von KI-generierten Inhalten** veroeffentlicht. Ziele:

- KI-generierte und manipulierte Inhalte sollen in **maschinenlesbaren, erkennbaren und interoperablen Formaten** gekennzeichnet werden.
- Deepfakes und KI-generierte Texte zu Themen von oeffentlichem Interesse sollen fuer Menschen identifizierbar sein.
- Kuenstlerische, kreative, satirische oder fiktionale Inhalte unterliegen reduzierten Transparenzpflichten.

### Pflichten nach dem AI Act (ab August 2026)

Wer ein KI-System einsetzt, das Texte generiert oder manipuliert, die mit dem Ziel veroeffentlicht werden, die Oeffentlichkeit ueber Angelegenheiten von oeffentlichem Interesse zu informieren, **muss offenlegen**, dass der Text kuenstlich generiert oder manipuliert wurde.

### Oeffentliche Erwartung

Studien der Landesmedienanstalten zeigen: **Neun von zehn Befragten** fordern verbindliche Kennzeichnungspflichten und zusaetzliche Transparenzmassnahmen wie freiwillige Verhaltensregeln oder externe Initiativen.

### Praxis in Redaktionen

- **Reuters**: Interne Richtlinien fuer verantwortungsvollen und transparenten KI-Einsatz.
- **BBC**: Menschliche Aufsicht ueber KI-generierte Inhalte; klare Kennzeichnung von KI-gestuetzter Berichterstattung.
- **AP**: Vertragliche Regelungen mit 90-Tage-Vorankuendigung vor Einfuehrung neuer KI-Technologien in der Redaktion.
- **The Onion / Wirecutter**: Gewerkschaften haben Vorab-Informationen und Transparenzpflichten bei KI-Beschaffung erfolgreich verhandelt.

---

## 4. Urheberrechtsfragen bei KI-generierten Texten

### Klagewelle gegen KI-Unternehmen

Die Zahl der Urheberrechtsklagen gegen KI-Unternehmen hat sich 2025 mehr als verdoppelt: von rund 30 Ende 2024 auf ueber 70.

### Wichtige Faelle im Ueberblick

**New York Times vs. OpenAI (eingereicht Dezember 2023)**
- Die NYT klagt gegen OpenAI und Microsoft wegen Urheberrechtsverletzung durch das Training von KI-Modellen mit NYT-Artikeln.
- Im Maerz 2025 wies ein Bundesrichter OpenAIs Antrag auf Klageabweisung zurueck -- der Fall geht weiter.
- OpenAI argumentiert mit "Fair Use"; die NYT sieht systematischen Diebstahl.
- Im Juni 2025 wurde OpenAI gerichtlich zur Aufbewahrung aller Output-Logdaten verpflichtet.

**New York Times vs. Perplexity AI (eingereicht Dezember 2024)**
- Die NYT verklagt Perplexity AI, weil dessen KI-Rechercheassistent Journalismus der NYT gestohlen habe -- nach 18 Monaten gescheiterter Lizenzverhandlungen.

**Perplexity AI -- Plagiatsvorwuerfe (2024)**
- **Forbes**: Fand eine plagiierte Version seiner Paywall-geschuetzten Exklusivrecherche in Perplexitys Pages-Tool.
- **Wired**: Dokumentierte, dass Perplexity ueber nicht deklarierte Web-Crawler mit gefaelschten User-Agent-Strings Inhalte scrapet, auch von Seiten, die Scraping explizit verbieten.
- **News Corp** (Wall Street Journal, New York Post u.a.) klagte gegen Perplexity.
- Als Reaktion fuehrte Perplexity ein Revenue-Sharing-Modell ein, an dem u.a. **Der Spiegel**, Fortune, Time und The Texas Tribune teilnehmen.

**Advance vs. Cohere (2025)**
- Der Verlag klagt, Coheres KI liefere wortwoertliche Kopien, umfangreiche Auszuege und substituierende Zusammenfassungen von Verlagsinhalten.
- Dies war eine der ersten Entscheidungen, die eine textbasierte Output-Kopie-Klage bei nicht-wortwortgetreuen Nachrichtenzusammenfassungen zuliess.

### Gemischte Gerichtsurteile

- **Anthropic (Bartz v. Anthropic)**: Ein Richter befand, Anthropics Nutzung von Buechern zum Training sei "Fair Use". Dennoch einigte sich Anthropic auf einen Vergleich von 1,5 Milliarden Dollar.
- Die Rechtslage bleibt insgesamt unklar und stark im Fluss.

---

## 5. Datenschutz und Quellenschutz

### Risiken fuer Journalisten bei der Nutzung von KI-Tools

**Datenlecks und Vertraulichkeit**
- ChatGPT hatte Sicherheitsvorfaelle, bei denen einigen Nutzern die Gespraechstitel anderer Nutzer angezeigt wurden.
- Fuer Journalisten, die mit sensiblen Quelleninformationen arbeiten, ist dies besonders problematisch.

**Trainingsdaten und Informationsspeicherung**
- Interne Daten, die in KI-Tools eingegeben werden (inklusive E-Mails, Recherchematerial, Dokumente), koennen verarbeitet, gespeichert und fuer kuenftiges Modelltraining verwendet werden.
- Vertrauliche Quelleninformationen koennten so in kuenftige KI-Modelle einfliessen.

**Verschluesselung und Ueberwachung**
- OpenAI arbeitet an clientseitiger Verschluesselung, deutet aber gleichzeitig automatisierte Systeme zur Erkennung von Sicherheitsproblemen an.
- Clientseitiges Scanning untergaebt Verschluesselung und erhoeht das Angriffsrisiko.

**Mangelnde Transparenz**
- Studien zeigen erhebliche Luecken im Verstaendnis der Nutzer ueber Datenpraktiken der KI-Anbieter.
- Bedenken bestehen bezueglich unautorisiertem Datenzugriff, langer Datenspeicherung und fehlender Transparenz.

### Empfehlungen fuer Journalisten

1. **Keine vertraulichen Quellen- oder Rechercheinformationen in KI-Tools eingeben** -- insbesondere nicht in cloudbasierte Dienste wie ChatGPT, Copilot oder Gemini.
2. **"Temporary Chat" oder aehnliche Funktionen nutzen**: ChatGPTs temporaerer Chat speichert Gespraeche nicht im Verlauf und nutzt sie nicht fuer Training (Aufbewahrung max. 30 Tage bei OpenAI).
3. **Lokale KI-Modelle in Betracht ziehen**: Fuer sensible Recherchen koennen lokal laufende Modelle (z.B. Ollama/Llama) eine sicherere Alternative sein.
4. **Datenschutzrichtlinien der Anbieter pruefen**: Vor dem Einsatz verstehen, wie Daten verarbeitet, gespeichert und weitergegeben werden.
5. **Redaktionelle KI-Richtlinien einhalten**: Klare interne Regeln, welche Informationen in KI-Tools eingegeben werden duerfen.

---

## 6. Fallbeispiele: Wenn KI im Journalismus schiefgeht

### CNET -- Fehlerhafte KI-Finanzartikel (2023)

- CNET veroeffentlichte 77 KI-generierte Erklaerungsartikel zu Finanzthemen unter dem Autorennamen "CNET Money Staff".
- **Mehr als die Haelfte** der Artikel musste nachtraeglich korrigiert werden.
- Die Fehler reichten von faktischen Ungenauigkeiten bis hin zu grundlegend falschen Erklaerungen von Finanzprodukten.
- Quelle: [Washington Post](https://www.washingtonpost.com/media/2023/01/17/cnet-ai-articles-journalism-corrections/)

### Sports Illustrated -- Fake-Autoren (2023)

- Sports Illustrated wurde im November 2023 entlarvt, Artikel unter fiktiven Autorennamen veroeffentlicht zu haben, deren Profile vollstaendig KI-generiert waren.
- Erfundene "Teammitglieder" wie **Drew Ortiz** und **Sora Tanaka** wurden mit falschen Biografien und Fachkompetenz ausgestattet.
- Die KI-generierten Kaufratgeber wurden ueber Affiliate-Links monetarisiert.
- Quelle: [Futurism](https://futurism.com/sports-illustrated-ai-generated-writers), [NPR](https://www.npr.org/2023/11/28/1215693615/sports-illustrated-is-accused-of-posting-articles-by-writers-created-by-ai)

### Gannett/USA Today -- Absurde Sportberichte (2023/2024)

- Der Medienkonzern Gannett setzte das Unternehmen **LedeAI** fuer automatisierte Sportberichterstattung ein.
- LedeAI fuegte wiederholt die Phrase "close encounter of the athletic kind" in High-School-Sportberichte ein.
- USA Today und andere Gannett-Zeitungen veroeffentlichten "hilariously garbled" (grotesk verstuesmmelte) KI-generierte Sport-Zusammenfassungen.
- Ein eigener Gannett-Sportjournalist bezeichnete die Ergebnisse als "peinlich".

### Google AI Overviews -- Gefaehrliche Fehlinformationen (2024/2025)

- Google fuehrte im Mai 2024 "AI Overviews" ein -- KI-generierte Zusammenfassungen ueber Suchergebnissen.
- **Beispiele fuer Halluzinationen**:
  - Die KI empfahl, Steine zu essen und Klebstoff auf Pizza zu tun (uebernommen aus satirischen Forum-Beitraegen).
  - Die KI behauptete, das aktuelle Jahr sei 2024 (im Jahr 2025).
  - Falsche Angaben zu NASA-Missionen mit veralteten Quellen.
- **Gesundheitsgefaehrdung**: Die Canadian Medical Association bezeichnete KI-generierte Gesundheitsratschlaege als "gefaehrlich".
- **Fake-News-Seiten**: Ueber 4.000 KI-generierte Fake-News-Seiten wurden identifiziert, die speziell fuer Google Discover erstellt wurden (Recherche des franzoesischen Mediums Next).

### Perplexity AI -- Systematisches Plagiat (2024)

- Forbes und Wired dokumentierten, dass Perplexity AI systematisch Paywall-geschuetzte Exklusivinhalte plagiierte.
- Perplexity nutzte nicht deklarierte Web-Crawler mit gefaelschten User-Agent-Strings.
- Die Inhalte wurden mit minimaler Quellenangabe reproduziert.
- Quelle: [TechCrunch](https://techcrunch.com/2024/07/02/news-outlets-are-accusing-perplexity-of-plagiarism-and-unethical-web-scraping/)

### Kernproblem: Halluzinationen

Das grundlegende Problem von KI-Sprachmodellen im Journalismus: Sie koennen menschliches Schreiben imitieren, haben aber **kein tatsaechliches Verstaendnis** des Geschriebenen. Dadurch fuegen sie haeufig Fehler und frei erfundene Informationen ein -- sogenannte "Halluzinationen".

---

## 7. Deutsche Regulierung und Richtlinien

### Deutscher Presserat

**Pressekodex-Ergaenzung (beschlossen September 2024, in Kraft seit Maerz 2025)**:
- Die Praeambel des Pressekodex wurde ergaenzt: Redaktionen tragen die presseethische Verantwortung fuer alle Beitraege, unabhaengig von der Art der Erstellung.
- **KI-Texte**: Keine zusaetzliche Kennzeichnungspflicht erforderlich.
- **KI-Bilder**: Muessen als Symbolbilder gekennzeichnet werden.
- Der gesamte Pressekodex gilt unveraendert auch fuer KI-generierte Inhalte -- inklusive Sorgfaltspflicht, Richtigkeit, Persoenlichkeitsrechte und Opferschutz.
- Quellen: [Presserat](https://www.presserat.de/presse-nachrichten-details/redaktionen-auch-fuer-ki-generierte-inhalte-ethisch-verantwortlich.html), [Meedia](https://meedia.de/news/beitrag/17700-auch-die-ki-muss-den-pressekodex-einhalten.html)

### Landesmedienanstalten

**Positionspapier "KI und Medien -- Vielfalt staerken, Verantwortung regeln, Vertrauen wahren"**:
- Die Direktorenkonferenz der Landesmedienanstalten (DLM) hat ein umfassendes Positionspapier zum KI-Einsatz in Medien beschlossen.
- Schwerpunkte: Vielfaltssicherung, Verantwortungsregelung und Vertrauenserhalt.
- Quelle: [die-medienanstalten.de](https://www.die-medienanstalten.de/service/positionspapiere/ki-und-medien-vielfalt-staerken-verantwortung-regeln-vertrauen-wahren/)

**Aufsichtszustaendigkeit**:
- Die Aufsicht ueber KI-Anwendungen in Rundfunk und Telemedien (einschliesslich Kennzeichnung von Deepfakes und KI-generierten Nachrichtentexten) liegt bei den **Landesmedienanstalten**, nicht bei der Bundesnetzagentur.

**Digitale Medien-Staatsvertrag (Entwurf Juni 2025)**:
- Die Rundfunkkommission der Laender plant einen neuen Digitale Medien-Staatsvertrag, der Vorgaben aus vier EU-Regelwerken umsetzen soll.
- Die Landesmedienanstalten werden fuer die Aufsicht ueber die Einhaltung der KI-Verordnung in Rundfunk und Telemedien zustaendig sein.
- Betreiber von KI-Systemen muessen Transparenz ueber Deepfakes aus Bild-, Ton- oder Videoinhalten herstellen.

**Forschung und oeffentliche Meinung**:
- Die Studie "Transparenz-Check: Wahrnehmung von KI-Journalismus" zeigt:
  - 90% der Befragten fordern verbindliche Kennzeichnungspflichten.
  - Zusaetzlich werden freiwillige Verhaltensregeln und externe Initiativen gefordert.
- Quelle: [die-medienanstalten.de](https://www.die-medienanstalten.de/pressemitteilungen/ki-im-journalismus-vertrauen-verspielt-oder-chance-genutzt/)

### KI-Durchfuehrungsgesetz (nationale Umsetzung des AI Act)

- Das Bundeskabinett hat ein AI Act Durchfuehrungsgesetz zur nationalen KI-Aufsicht verabschiedet.
- Die Landesmedienanstalten bleiben fuer den Medienbereich zustaendig.
- Quelle: [aiact-akademie.de](https://www.aiact-akademie.de/de/aktuelles/ai-act-durchfuehrungsgesetz-bundeskabinett-ki-aufsicht)

---

## 8. Quellen

### Richtlinien und Positionen von Medienorganisationen
- [Researchers compare AI policies and guidelines at 52 news organizations](https://journalistsresource.org/home/generative-ai-policies-newsrooms/) -- Journalist's Resource
- [AI and the news: What researchers learned from the AP + the BBC](https://journalistsresource.org/home/ai-ap-bbc/) -- Journalist's Resource
- [AI and the Future of News](https://reutersinstitute.politics.ox.ac.uk/ai-journalism-future-news) -- Reuters Institute
- [Pressekodex](https://www.presserat.de/pressekodex.html) -- Deutscher Presserat
- [Redaktionen auch fuer KI-generierte Inhalte ethisch verantwortlich](https://www.presserat.de/presse-nachrichten-details/redaktionen-auch-fuer-ki-generierte-inhalte-ethisch-verantwortlich.html) -- Deutscher Presserat
- [Pressekodex gilt auch fuer KI-Inhalte](https://www.kom.de/news-praxis/pressekodex-gilt-auch-fuer-ki-inhalte/) -- KOM Magazin

### EU AI Act
- [The EU, AI and Journalism](https://europeanjournalists.org/blog/2024/10/10/the-eu-ai-and-journalism/) -- European Federation of Journalists
- [The AI Act's Code of Practice is Europe's last opportunity to protect journalism](https://rsf.org/en/ai-act-s-code-practice-europe-s-last-opportunity-protect-journalism-tech-industrys-interests) -- Reporter ohne Grenzen (RSF)
- [The AI Act's Extended Timeline Is Perilous for Journalism](https://www.cigionline.org/articles/the-ai-acts-extended-timeline-is-perilous-for-journalism-and-democracy/) -- CIGI
- [Navigating the New Frontier: How the EU AI Act Will Impact the Media Industry](https://babl.ai/navigating-the-new-frontier-how-the-eu-ai-act-will-impact-the-media-industry/) -- BABL AI

### Transparenz und Kennzeichnung
- [Commission publishes first draft of Code of Practice on marking and labelling of AI-generated content](https://digital-strategy.ec.europa.eu/en/news/commission-publishes-first-draft-code-practice-marking-and-labelling-ai-generated-content) -- EU Digital Strategy
- [AI labeling requirement starting in 2026](https://weventure.de/en/blog/ai-labeling) -- WeVenture

### Urheberrecht und Klagen
- [AI Copyright Lawsuit Developments in 2025](https://copyrightalliance.org/ai-copyright-lawsuit-developments-2025/) -- Copyright Alliance
- [Court Rules AI News Summaries May Infringe Copyright](https://copyrightlately.com/court-rules-ai-news-summaries-may-infringe-copyright/) -- Copyright Lately
- [Judge allows NYT copyright case against OpenAI to go forward](https://www.npr.org/2025/03/26/nx-s1-5288157/new-york-times-openai-copyright-case-goes-forward) -- NPR
- [News outlets accusing Perplexity of plagiarism](https://techcrunch.com/2024/07/02/news-outlets-are-accusing-perplexity-of-plagiarism-and-unethical-web-scraping/) -- TechCrunch
- [Perplexity AI will share revenue with publishers](https://www.cnbc.com/2024/07/30/perplexity-ai-to-share-revenue-with-publishers-after-plagiarism-accusations.html) -- CNBC

### Datenschutz
- [Artificial Insecurity: how AI tools compromise confidentiality](https://www.accessnow.org/artificial-insecurity-compromising-confidentality/) -- Access Now
- [How to Protect Your Privacy From ChatGPT](https://www.mozillafoundation.org/en/privacynotincluded/articles/how-to-protect-your-privacy-from-chatgpt-and-other-ai-chatbots/) -- Mozilla Foundation

### Fallbeispiele
- [CNET used AI to write articles. It was a journalistic disaster.](https://www.washingtonpost.com/media/2023/01/17/cnet-ai-articles-journalism-corrections/) -- Washington Post
- [Sports Illustrated Published Articles by Fake, AI-Generated Writers](https://futurism.com/sports-illustrated-ai-generated-writers) -- Futurism
- [Tests Show Top AI Models Are Making Disastrous Errors When Used for Journalism](https://futurism.com/ai-models-disastrous-errors-journalism) -- Futurism
- [Google Discover promotes AI-generated fake news sites](https://rsf.org/en/google-discover-promotes-ai-generated-fake-news-sites-detriment-trustworthy-media) -- RSF

### Deutsche Regulierung
- [Medienanstalten positionieren sich zu KI und Medien](https://www.die-medienanstalten.de/pressemitteilungen/positionspapier-ki/) -- die medienanstalten
- [KI und Medien -- Vielfalt staerken, Verantwortung regeln, Vertrauen wahren](https://www.die-medienanstalten.de/service/positionspapiere/ki-und-medien-vielfalt-staerken-verantwortung-regeln-vertrauen-wahren/) -- die medienanstalten
- [KI im Journalismus: Vertrauen verspielt oder Chance genutzt?](https://www.die-medienanstalten.de/pressemitteilungen/ki-im-journalismus-vertrauen-verspielt-oder-chance-genutzt/) -- die medienanstalten
- [AI Act Durchfuehrungsgesetz](https://www.aiact-akademie.de/de/aktuelles/ai-act-durchfuehrungsgesetz-bundeskabinett-ki-aufsicht) -- AI Act Akademie
- [Mit KI generierte Bilder muessen gekennzeichnet werden](https://www.presserat.de/presse-nachrichten-details/ruegen-fuer-verstoesse-gegen-die-sorgfaltspflicht-und-den-opferschutz.html) -- Deutscher Presserat
