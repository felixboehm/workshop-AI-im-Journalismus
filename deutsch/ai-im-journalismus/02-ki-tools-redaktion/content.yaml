version: 1
number: 2
title: "KI-Tools im Redaktionsalltag"
description: "Welche KI-Werkzeuge Redaktionen konkret einsetzen"
sections:
  - title: "Grosse Sprachmodelle (LLMs)"
    explanation: |
      Large Language Models sind die Basis vieler KI-Anwendungen im Journalismus:

      - **ChatGPT (OpenAI)**: Textzusammenfassungen, Recherche-Unterstuetzung, Ideenfindung, Datenanalyse
      - **Claude (Anthropic)**: Lange Kontextfenster fuer Dokumentenanalyse, differenzierte Textarbeit
      - **Perplexity AI**: Echtzeit-Webrecherche mit Quellenangaben, Deep-Research-Modus
      - **Google Gemini**: Integration mit Google-Oekosystem, multimodale Faehigkeiten

      OpenAI hat 2025 die "OpenAI Academy for News Organizations" gegruendet -- ein Programm mit
      finanziellen Zuschlaegen, technischem Support und Zugang zu den neuesten Modellen.
    examples:
      - q: "Eine Reporterin muss 200 Seiten Gerichtsakten bis morgen frueh auswerten. Welches LLM wuerde sich eignen und warum?"
        a: "Claude von Anthropic waere hier die beste Wahl -- es bietet besonders lange Kontextfenster und kann umfangreiche Dokumente in einem Durchgang analysieren. Wichtig: Die Ergebnisse muessen trotzdem gegen die Originalakten geprueft werden, da auch Claude halluzinieren kann"
        rel:
          - ["Claude", "Lange Kontextfenster fuer Dokumentenanalyse"]
          - ["Dokumentenanalyse", "KI-gestuetzte Auswertung grosser Textmengen"]

      - q: "Ein Faktencheck-Team sucht ein Tool, das Quellen direkt mitliefert. Warum reicht ChatGPT dafuer nicht?"
        a: "ChatGPT generiert Antworten aus Trainingsdaten und verlinkt standardmaessig keine Quellen -- es kann Quellen sogar erfinden. Perplexity AI dagegen recherchiert in Echtzeit im Web und liefert zu jeder Aussage verifiable Quellenangaben. Fuer Faktenchecks ist die Rueckverfolgbarkeit zur Originalquelle entscheidend"
        rel:
          - ["Perplexity AI", "Echtzeit-Webrecherche mit Quellenangaben"]
          - ["Quellenverifizierung", "Rueckverfolgbarkeit als Qualitaetskriterium"]

      - q: "Die OpenAI Academy bietet Redaktionen finanzielle Zuschlaege und technischen Support. Sollte eine Redaktion dieses Angebot annehmen?"
        a: "Das Angebot kann nuetzlich sein, aber Redaktionen sollten die Abhaengigkeit von einem einzigen Anbieter kritisch pruefen. Die NYT verklagt OpenAI gleichzeitig wegen Urheberrechtsverletzung. Eine strategische KI-Integration nutzt verschiedene Tools je nach Aufgabe, statt sich an ein Oekosystem zu binden"
        rel:
          - ["Anbieter-Abhaengigkeit", "Diversifikation statt Bindung an einen KI-Anbieter"]

      - q: "Fuer welche journalistische Aufgabe waere Google Gemini besser geeignet als ein reines Textmodell?"
        a: "Fuer multimodale Aufgaben wie die Analyse eines Fotos von einer Demonstration (Schaetzung der Teilnehmerzahl, Identifikation von Bannern) oder die Auswertung von Infografiken in fremdsprachigen Dokumenten. Geminis Staerke liegt in der Kombination von Bild-, Text- und Sprachverstaendnis innerhalb des Google-Oekosystems"
        rel:
          - ["Multimodale KI", "Verarbeitung verschiedener Medientypen"]

  - title: "Transkription und Uebersetzung"
    explanation: |
      **79% der Redaktionen** nutzen automatisierte Transkription fuer Interviews. Die wichtigsten Tools:

      - **Trint**: 50+ Sprachen, DSGVO-konform, trainiert nicht mit Nutzerdaten -- Standard bei AFP und Guardian
      - **Otter.ai**: Automatische Meeting-Teilnahme und Zusammenfassungen (Datenschutzbedenken -- Guardian hat Nutzung untersagt)
      - **OpenAI Whisper**: Open-Source-Modell mit 680.000 Stunden Trainingsdaten, Basis fuer viele andere Tools
      - **DeepL / DeepL Write**: Uebersetzung und Textoptimierung, besonders stark fuer Deutsch

      **Wichtig:** Trint bietet eine "No-Training"-Policy und die Wahl zwischen EU- und
      US-Datenspeicherung -- ein entscheidender Vorteil fuer den Quellenschutz.
    examples:
      - q: "Die AFP nutzte Trint bei der COP28 in Dubai fuer Live-Transkriptionen. Warum nicht einfach Otter.ai, das ebenfalls automatisch transkribiert?"
        a: "Trint bietet eine No-Training-Policy und EU-Datenspeicherung -- die Inhalte politischer Statements fliessen nicht ins Modelltraining ein. Otter.ai hat keine vergleichbare Garantie -- der Guardian hat Otter.ai deshalb sogar explizit verboten. Bei oeffentlichen politischen Reden mag das Risiko gering sein, aber eine Redaktion braucht einheitliche Standards"
        rel:
          - ["Datenschutz bei Transkription", "No-Training-Policy als Differenzierungsmerkmal"]

      - q: "Ein investigativer Reporter moechte ein vertrauliches Interview mit einem Whistleblower transkribieren. Welches Tool kommt in Frage?"
        a: "Keines der Cloud-basierten Tools -- weder Trint noch Otter.ai. Fuer hochsensible Inhalte sollte OpenAI Whisper lokal installiert werden (Open-Source, laeuft auf dem eigenen Rechner). Die Daten verlassen nie das Geraet. Der Quellenschutz geht hier vor Bequemlichkeit"
        rel:
          - ["Lokale Transkription", "Whisper lokal fuer sensible Inhalte"]
          - ["Quellenschutz", "Vertrauliche Daten nie in Cloud-Dienste"]

      - q: "Eine deutsche Redaktion erhaelt ein franzoesischsprachiges Leak-Dokument. Wie kann KI bei der Auswertung helfen, ohne den Inhalt zu gefaehrden?"
        a: "Schritt 1: DeepL fuer eine erste Uebersetzung oeffentlich zugaenglicher Teile. Schritt 2: Fuer sensible Passagen ein lokales Modell (z.B. Ollama mit einem Uebersetzungsmodell) nutzen. Wichtig: Nie das gesamte Dokument in einen Cloud-Dienst hochladen, sondern nur einzelne, nicht-identifizierbare Passagen"
        rel:
          - ["Gestufte Sicherheit", "Verschiedene Tools je nach Sensibilitaet des Materials"]

      - q: "Whisper ist Open Source und kostenlos. Warum zahlen Redaktionen trotzdem fuer Trint?"
        a: "Whisper ist die Basis-Technologie, Trint baut darauf auf und bietet Mehrwert fuer den Redaktionsalltag: Integration in Produktionssysteme, 50+ Sprachen, Sprecheridentifikation, Suchfunktion in Transkripten und DSGVO-konforme Infrastruktur. Fuer eine einzelne Transkription reicht Whisper -- fuer den taeglichen Redaktionsbetrieb braucht man Workflow-Integration"
        rel:
          - ["Open Source vs. Enterprise", "Basistechnologie vs. redaktioneller Workflow"]

  - title: "Spezial-Tools fuer den Journalismus"
    explanation: |
      Neben allgemeinen KI-Tools gibt es Werkzeuge, die speziell fuer den Journalismus entwickelt wurden:

      - **Google Pinpoint**: Kostenlos, analysiert bis zu 200.000 Dokumente, erkennt Personen/Orte/Organisationen, transkribiert Audio/Video -- der Boston Globe gewann damit einen Pulitzer-Preis
      - **dpa-News Hub**: KI-Rechercheassistent, der nur auf verifizierte dpa-Quellen zugreift
      - **Djinn (Norwegen)**: Durchsucht tausende Kommunaldokumente fuer die Lokalberichterstattung
      - **LocalLens**: Transkribiert und fasst lokale Regierungssitzungen zusammen
      - **Dataminr**: Echtzeit-Erkennung von Events und Breaking News vor Viralitaet
      - **Rolli Information Tracer**: Verfolgt die Verbreitung von Informationen ueber verschiedene Plattformen
    examples:
      - q: "Maria Ressa verarbeitete 13.000 CIA-Dokumente in 30 Minuten mit Google Pinpoint. Wie geht das konkret?"
        a: "Pinpoint erkennt automatisch Personen, Organisationen und Orte in Dokumenten und macht sie durchsuchbar. Statt 13.000 Dokumente einzeln zu lesen, kann man gezielt nach Namen, Verbindungen und Mustern suchen. Der Boston Globe nutzte Pinpoint aehnlich fuer seine Pulitzer-Preis-gekroente Recherche 2021 -- das Tool ist kostenlos fuer Journalist:innen"
        rel:
          - ["Google Pinpoint", "Dokumentenanalyse fuer investigative Recherche"]

      - q: "Eine Lokalreporterin in Niedersachsen kann nicht alle Gemeinderatssitzungen besuchen. Gibt es dafuer KI-Loesungen?"
        a: "Ja -- Tools wie LocalLens transkribieren und fassen lokale Regierungssitzungen zusammen. Das norwegische Djinn durchsucht tausende Kommunaldokumente und identifiziert Schluesselinformationen. In Deutschland koennte eine Kombination aus Whisper-Transkription und LLM-Zusammenfassung einen aehnlichen Workflow ermoeglichen"
        rel:
          - ["Lokaljournalismus", "KI-Unterstuetzung bei der Kommunalberichterstattung"]

      - q: "Ein Redakteur bemerkt einen Tweet, der viral geht und eine politische Behauptung enthaelt. Wie kann er schnell pruefen, woher die Behauptung stammt?"
        a: "Der Rolli Information Tracer verfolgt die Verbreitung von Informationen ueber verschiedene Plattformen und identifiziert den Ursprung von Behauptungen. Dataminr haette den Tweet moeglicherweise schon vor der Viralitaet erkannt. Beide Tools zusammen erm√∂glichen: Frueherkennung, Quellenrueckverfolgung und Analyse, wie sich der Inhalt beim Teilen veraendert hat"
        rel:
          - ["Information Tracking", "Verfolgung von Informationsverbreitung"]

      - q: "Warum entwickeln Nachrichtenorganisationen eigene KI-Tools wie den dpa-News Hub statt einfach ChatGPT zu nutzen?"
        a: "Weil allgemeine LLMs keine Quellengarantie bieten und halluzinieren koennen. Der dpa-News Hub greift ausschliesslich auf verifizierte dpa-Quellen zu -- jede Antwort ist belegbar. Fuer eine Nachrichtenagentur, deren Geschaeftsmodell auf Vertrauenswuerdigkeit basiert, ist die Kontrolle ueber die Datenbasis keine Option, sondern Voraussetzung"
        rel:
          - ["Eigene KI-Systeme", "Kontrollierte Datenbasis fuer vertrauenswuerdige Ergebnisse"]

  - title: "Fact-Checking-Tools"
    explanation: |
      Dedizierte KI-Tools unterstuetzen Journalist:innen beim Faktencheck:

      - **Full Fact AI**: Transkribiert Audio/Video mit Echtzeit-Erkennung von Falschinformationen, eingesetzt von 45+ Organisationen in 30 Laendern
      - **ClaimBuster**: Analysiert politische Reden und Debatten, extrahiert automatisch ueberpruefelswerte Behauptungen (Duke Reporter's Lab)
      - **Logically Facts**: Professionelles Fact-Checking mit KI-gestuetzter Priorisierung

      **Wichtig:** Diese Tools unterstuetzen den Faktencheck -- die finale Bewertung bleibt
      immer beim Menschen.
    examples:
      - q: "Waehrend einer Bundestagsdebatte fallen dutzende Behauptungen. Wie kann ein Faktencheck-Team in Echtzeit priorisieren?"
        a: "Full Fact AI transkribiert die Debatte live und flaggt automatisch potenziell falsche Behauptungen. ClaimBuster ergaenzt, indem es 'check-worthy claims' identifiziert -- also Aussagen, die faktisch ueberpruefbar sind (im Gegensatz zu Meinungen). Das Team kann sich auf die relevantesten Behauptungen konzentrieren statt alles manuell zu filtern"
        rel:
          - ["Echtzeit-Faktencheck", "KI-gestuetzte Priorisierung bei Live-Events"]

      - q: "Full Fact AI wird von 45+ Organisationen in 30 Laendern eingesetzt. Warum vertrauen so viele darauf, obwohl KI selbst fehleranfaellig ist?"
        a: "Weil Full Fact AI nicht selbst Fakten prueft, sondern Hinweise liefert: Es erkennt Behauptungen, die moeglicherweise falsch sind, und markiert sie fuer menschliche Faktenpruefer:innen. Das Tool ersetzt nicht den Faktencheck, sondern macht ihn skalierbarer -- wie ein Vorfilter, der die Nadel im Heuhaufen eingrenzt"
        rel:
          - ["KI als Vorfilter", "Skalierung durch maschinelle Vorselektion"]

      - q: "Ein Politiker behauptet in einem Interview, die Kriminalitaet sei um 30% gestiegen. Wie wuerde ein KI-gestuetzter Faktencheck-Workflow aussehen?"
        a: "ClaimBuster identifiziert die Behauptung als 'check-worthy'. Dann recherchiert der Journalist die Originaldaten (z.B. PKS des BKA). Perplexity kann als Recherche-Unterstuetzung mit Quellenangaben dienen. Die finale Bewertung -- ob die Zahl stimmt, welcher Zeitraum gemeint ist, ob sie im Kontext irrefuehrend ist -- bleibt beim Menschen"
        rel:
          - ["Faktencheck-Workflow", "Mehrstufiger Prozess von der Erkennung zur Bewertung"]

      - q: "Kann man sich auf KI-Fact-Checking verlassen, wenn KI-Chatbots selbst Halluzinationsraten von bis zu 79% haben?"
        a: "Nein -- deshalb sind Fact-Checking-Tools anders aufgebaut als Chatbots. ClaimBuster identifiziert nur, welche Behauptungen pruefenswert sind, es bewertet sie nicht selbst. Full Fact gleicht Aussagen mit Datenbanken ab. Das Prinzip ist: KI filtert und priorisiert, der Mensch verifiziert. Ein Chatbot, der frei halluziniert, ist kein Fact-Checking-Tool"
        rel:
          - ["Architektur-Unterschied", "Fact-Checking-Tools vs. allgemeine Chatbots"]
